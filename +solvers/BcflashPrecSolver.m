classdef BcflashPrecSolver < solvers.BcflashSolver
    %% BcflashPrecSolver
    %  Extention of BcflashSolver for the use of a preconditioner
    %  The method propose a version of the TRON algorithm where the
    %  descent directions for the cauchy point and the conjugate gradient
    %  are transformed through the use of a preconditioner.
    %
    %  The model must contain the following methods
    %
    %        * precTimes
    %        * precSubTimes
    %
    %  to compute either the product of a vector by the
    %  preconditioner (y = M * x) or by its principal submatrices
    %  (w = M(ind,ind) * v).
    %
    %  This algorithm also has embedded logging, through the use of the
    %  loggin4matlab package, available at
    %  https://github.com/optimizers/logging4matlab
    %  The repository should be located under the parent repository of the
    %  current folder.

    methods (Access = public)
        
        function self = BcflashPrecSolver(nlp, varargin)
            %% Constructor
            self = self@solvers.BcflashSolver(nlp, varargin{:});
        end % constructor

        
        function x = project(self, x, ind)
            %% Project
            % Project a vector onto the box defined by bL, bU.
            if nargin > 2
                x = min(self.nlp.bU(ind), max(x, self.nlp.bL(ind)));
            else
                x = min(self.nlp.bU, max(x, self.nlp.bL));
            end
        end
        
    end % public methods
    
    
    methods (Access = protected)
        
        function [x, s] = spcg(self, H, x, g, delta, s)
            %% SPCG - Minimize a bound-constraint quadratic
            %
            % This subroutine generates a sequence of approximate
            % minimizers for the subproblem
            %
            %       min { q(x) : bL <= x <= bU }.
            %
            % The quadratic is defined by
            %
            %       q(x[0]+s) = 0.5*s'*H*s + g'*s,
            %
            % where x[0] is a base point provided by the user, H is an
            % opSpot of the hessian, and g is  a
            % vector.
            %
            % At each stage we have an approximate minimizer x[k], and
            % generate a direction p[k] by using a preconditioned conjugate
            % gradient method on the subproblem
            %
            %       min { q(x[k]+p) : || L'*p || <= delta, s(fixed) = 0 },
            %
            % where fixed is the set of variables fixed at x[k] and delta
            % is the trust region bound.
            %
            % Given p[k], the next minimizer x[k+1] is generated by a
            % projected search.
            %
            % The starting point for this subroutine is x[1] = x[0] + s,
            % where x[0] is a base point and s is the Cauchy step.
            %
            % The subroutine converges when the step s satisfies
            %
            %       || (g + H*s)[free] || <= rTol*|| g[free] ||
            %
            % In this case the final x is an approximate minimizer in the
            % face defined by the free variables.
            %
            % The subroutine terminates when the trust region bound does
            % not allow further progress, that is, || p[k] || = delta.
            % In this case the final x satisfies q(x) < q(x[k]).
            
            self.logger.debug('-- Entering SPCG --');
            % Compute the Cauchy point
            x = x + s;
            Hs = H * s;
            
            % There are at most n iters because at each iter
            % at least one variable becomes active.
            iters = 1;
            for nFaces = 1 : self.nlp.n
                
                % Determine the free variables at the current minimizer.
                % The indices of the free variables are stored in the first
                % n free positions of the array indFree.
                indFree = self.getIndFree(x);
                
                % Exit if there are no free constraints
                if ~any(indFree)
                    break;
                end
                
                % Compute the gradient grad q(x[k]) = g + H*(x[k] - x[0]),
                % of q at x[k] for the free variables.
                % Recall that w contains  H*(x[k] - x[0]).
                % Compute the norm of the reduced gradient Z'*g.
                
                wa = g(indFree);
                gQuad = Hs(indFree) + wa;
                
                % Reduced preconditioned direction
                ptw = wa.' * self.nlp.precSubTimes(wa, indFree);
                
                % Solve the trust region subproblem in the free variables
                % to generate a direction p[k]. Store p[k] in the array w.
                tol = self.cgTol * ptw;
                
                Hfree = H(indFree, indFree);
                
                [w, iterTR, infoTR] = self.trpcg(Hfree, gQuad, indFree, ...
                    delta, tol, self.maxIterCg, s(indFree));
                iters = iters + iterTR;
                
                % Use a projected search to obtain the next iterate.
                % The projected search algorithm stores s[k] in w.
                w = self.prsrch(Hfree, x(indFree), gQuad, w, ...
                    indFree);
                
                % Update the minimizer and the step.
                % Note that s now contains x[k+1] - x[0].
                x(indFree) = x(indFree) + w;
                s(indFree) = s(indFree) + w;
                
                % Compute A*(x[k+1] - x[0]) and store in w.
                Hs = H * s;
                newwa = (wa + Hs(indFree));
                normWa = newwa.' * self.nlp.precSubTimes(newwa, indFree);
                
                % Convergence and termination test.
                % We terminate if the preconditioned conjugate gradient
                % method encounters a direction of negative curvature, or
                % if the step is at the trust region bound.
                if normWa <= tol || infoTR == 2 || ...
                        infoTR == 3 || iters > self.maxIterCg || ...
                        toc(self.solveTime) >= self.maxRT
                    self.logger.debug('Leaving SPCG');
                    break;
                end
            end % faces
            self.iterCg = self.iterCg + iters;
        end % spcg
        
        function p = descentDirection(self, x, g)
            %% descentDirection
            %  This method computes a direction of the form
            %
            %        p = P*C*Ct*P*g
            %
            %  where p is the projection onto the constraint set associated
            %  to the indices
            %
            %        I = {i |   x_i == bU_i and g_i < 0
            %                or x_i == bL_i and g_i > 0}
            %
            %  The set is represents the constraints that are violated by
            %  an arbitrarily small step in  the direction -g.
            %  The use of projections is equivalent to remove some rows and
            %  columns to the matrix M
            
            Iplus = ((self.nlp.bU == x) & (g < 0) |...
                (x == self.nlp.bL) & (g > 0));
            
            p = g;
            p(Iplus) = 0;
            p = self.nlp.precTimes(p);
            p(Iplus) = 0;
        end
        
        function [w, iters, info] = trpcg(self, H, g, indFree, delta, ...
                                          tol, iterMax, s)
            %% TRPCG - Trust-region projected conjugate gradient
            % This subroutine uses a truncated conjugate gradient method to
            % find an approximate minimizer of the trust-region subproblem
            %
            %       min { q(s) : ||s|| <= delta }.
            %
            % where q is the quadratic
            %
            %       q(s) = 0.5*s'*H*s + g'*s,
            %
            % H is an opSpot of the reduced hessian and g is a vector.
            %
            % Termination occurs if the conjugate gradient iterates leave
            % the trust region, a negative curvature direction is
            % generated, or one of the following two convergence tests is
            % satisfied.
            %
            % Convergence in the original variables:
            %
            %       || grad q(s) || <= tol
            %
            % On exit info is set as follows:
            %
            %       info = 1  Convergence in the original variables.
            %                 || grad q(s) || <= tol
            %
            %       info = 2  Negative curvature direction generated.
            %                 In this case || w || = delta.
            %
            %       info = 3  Conjugate gradient iterates exit the
            %                 trust region. In this case || w || = delta.
            %
            %       info = 4  Failure to converge within iterMax iters.
            
            self.logger.debug('-- Entering TRPCG --');
            self.logger.debug(sprintf( ...
                'tol = %7.3e, δ = %7.3e,', tol, delta));
            
            n = length(g);
            % Initialize the iterate w and the residual r.
            w = zeros(n, 1);
            % Initialize the residual r of grad q to -g.
            r = -g;
            % Initialize the preconditioned search direction
            z = self.nlp.precSubTimes(r, indFree);
            % Initialize the direction p.
            p = z;
            % Initialize rho and the norms of r and t.
            rho = r' * z;
            rnorm0 = norm(r);
            
            % Exit if g = 0.
            if rnorm0 == 0
                iters = 0;
                info = 1;
                self.logger.debug(sprintf(['Leaving TRPCG, info', ...
                    '= %d (conv)'], info));
                return
            end
            
            for iters = 1:iterMax
                Hp = H * p;
                q = Hp;
                % Compute alph and determine sigma such that the TR
                % constraint || w + sigma*p || = delta is satisfied.
                ptq = p' * q;
                self.logger.debug(sprintf('\tp''*H*p = %7.3e', ptq));
                if ptq > 0
                    alph = rho / ptq;
                else
                    alph = 0;
                end
                sigma = solvers.BcflashPrecSolver.trqsol(w + s, p, delta);
                % Exit if there is negative curvature or if the
                % iterates exit the trust region.
                self.logger.debug(sprintf('\tαCG = %7.1e, σ = %7.1e', ...
                    alph, sigma));
                if (ptq <= 0 || alph >= sigma)
                    if sigma ~= 0
                        w = w + sigma*p;
                    end
                    if ptq <= 0
                        info = 2;
                        self.logger.debug(sprintf( ...
                            ['Leaving TRPCG, info', ...
                            ' = %d (negative curv)'], info));
                    else
                        info = 3;
                        self.logger.debug(sprintf( ...
                            ['Leaving TRPCG, info', ...
                            ' = %d (exit TR)'], info));
                    end
                    return
                end
                % Update w and the residuals r.
                w = w + alph * p;
                r = r - alph * q;
                
                % Compute the new preconditioned direction
                z = self.nlp.precSubTimes(r, indFree);
                rtz = r.' * z;
                
                % Exit if the residual convergence test is satisfied.
                rnorm = norm(r);
                self.logger.debug(sprintf('\t||r''*r|| = %7.3e', rnorm));
                if abs(rtz) <= tol
                    info = 1;
                    self.logger.debug(sprintf(['Leaving TRPCG, info', ...
                        ' = %d (conv)'], info));
                    return
                end
                
                
                
                % Compute p = r + betaFact*p and update rho.
                betaFact = rtz / rho;
                p = z + betaFact * p;
                rho = rtz;
            end % for loop
            
            info = 4;
            self.logger.debug(sprintf( ...
                'Leaving TRPCG, info = %d (fail)', info));
        end % trpcg
        
    end % private methods
    
    
    methods (Access = public, Hidden = true)
        
        function printf(self, varargin)
            fprintf(self.fid, varargin{:});
        end
        
    end % hidden public methods
    
end % class
